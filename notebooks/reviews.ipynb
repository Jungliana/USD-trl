{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(sample):\n",
    "    sample[\"query\"] = \" \".join(sample[\"text\"].split()[: 5])\n",
    "    return sample\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\", split=\"test\")\n",
    "dataset = dataset.filter(lambda x: len(x[\"text\"]) > 80, batched=False)\n",
    "dataset = dataset.filter(lambda x: len(x[\"text\"]) < 120, batched=False)\n",
    "dataset = dataset.filter(lambda x: x[\"label\"] < 4, batched=False)\n",
    "dataset = dataset.filter(lambda x: x[\"label\"] > 0, batched=False)\n",
    "dataset = dataset.map(cut, batched=False)\n",
    "train_ds, test_ds = train_test_split(dataset,\n",
    "                 test_size=0.99,\n",
    "                 random_state=2345)\n",
    "del train_ds['label']\n",
    "del train_ds['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load a pretrained model\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(\"Zohar/distilgpt2-finetuned-restaurant-reviews\")\n",
    "model_ref = AutoModelForCausalLMWithValueHead.from_pretrained(\"Zohar/distilgpt2-finetuned-restaurant-reviews\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Zohar/distilgpt2-finetuned-restaurant-reviews\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    \"max_new_tokens\": 25,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"
     ]
    }
   ],
   "source": [
    "reward_tokenizer = AutoTokenizer.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\", model_max_length=256)\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\", model=reward_model, device=device, tokenizer=reward_tokenizer)\n",
    "sent_kwargs = {\"top_k\": None, \"function_to_apply\": \"softmax\", \"batch_size\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------\n",
      "Query: The outside and the inside\n",
      "Response: The outside and the inside are wonderful. You can tell by the color of building with zig zags of chalk together making you feel like you are\n",
      "Reward: 0.9553338885307312\n",
      "\n",
      "----------------------------\n",
      "Query: Two Words: Frozen Cosmos\\n\\nYou need\n",
      "Response: Two Words: Frozen Cosmos\\n\\nYou need to study Greek 'Holy Bread House'\n",
      "\n",
      "If you're a Diet, do yourself a favor and go to this Vietnamese\n",
      "Reward: 0.0942615270614624\n",
      "\n",
      "----------------------------\n",
      "Query: Food was good. Service was\n",
      "Response: Food was good. Service was ok. Duck salad was a little dry with low carb and not too spicy!\n",
      "The BBQ Sandwich was the perfect shave for\n",
      "Reward: 0.983796238899231\n",
      "\n",
      "----------------------------\n",
      "Query: Nice salad bar. Reminds me\n",
      "Response: Nice salad bar. Reminds me of how I was in central Columbus.  .   Overall was good but cruise.    Husband was\n",
      "Reward: 0.9850949048995972\n",
      "\n",
      "----------------------------\n",
      "Query: We got the spa suite,\n",
      "Response: We got the spa suite, and I ate the large pieces of mojum to start. This place is a nice perk to me as I have a\n",
      "Reward: 0.9898834824562073\n",
      "\n",
      "----------------------------\n",
      "Query: Good place to go to\n",
      "Response: Good place to go to very excited about its growing popularity throughout Portland. This is a local place with a local vibe and a real neighborhood atmosphere but not\n",
      "Reward: 0.9909582138061523\n",
      "\n",
      "----------------------------\n",
      "Query: excellent but expensive pizza. impersonal\n",
      "Response: excellent but expensive pizza. impersonal, and insanely cheap, with two people taking a photo and up from 11PM until 5AM.\n",
      "\n",
      "Biscuits\n",
      "Reward: 0.7254109978675842\n",
      "\n",
      "----------------------------\n",
      "Query: This place was not good.\n",
      "Response: This place was not good. I was impressed by most of the dishes but didn't wipe off my plate to leave. \n",
      "\n",
      "Roasted beef Borg\n",
      "Reward: 0.0027809327002614737\n",
      "\n",
      "----------------------------\n",
      "Query: It's a Taco Bell and\n",
      "Response: It's a Taco Bell and the salsa is very good. Not the soup I wanted, but its just trying to find something authentic albeit less interesting to me\n",
      "Reward: 0.8224859833717346\n"
     ]
    }
   ],
   "source": [
    "# 2. initialize trainer\n",
    "ppo_config = {\"batch_size\": 1}\n",
    "config = PPOConfig(**ppo_config)\n",
    "ppo_trainer = PPOTrainer(config, model, model_ref, tokenizer)\n",
    "\n",
    "for query_txt in train_ds['query']:\n",
    "    # 3. encode a query\n",
    "    print(\"\\n----------------------------\")\n",
    "    print(f\"Query: {query_txt}\")\n",
    "    query_tensor = tokenizer.encode(query_txt, return_tensors=\"pt\").to(model.pretrained_model.device)\n",
    "\n",
    "    # 4. generate model response\n",
    "    response_tensor = ppo_trainer.generate([item for item in query_tensor], return_prompt=True, **generation_kwargs)\n",
    "    response_txt = tokenizer.decode(response_tensor[0], skip_special_tokens=True)\n",
    "    print(f'Response: {response_txt}')\n",
    "\n",
    "    # 5. define a reward for response\n",
    "    # (this could be any reward such as human feedback or output from another model)\n",
    "    pipe_outputs = sentiment_pipe(response_txt, **sent_kwargs)\n",
    "    reward = [torch.tensor(next(val for val in pipe_outputs if val[\"label\"] == \"POS\")['score'], device=model.pretrained_model.device)]\n",
    "    print(f'Reward: {reward[0].item()}')\n",
    "\n",
    "    # 6. train model with ppo\n",
    "    train_stats = ppo_trainer.step([query_tensor[0]], [response_tensor[0]], reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
